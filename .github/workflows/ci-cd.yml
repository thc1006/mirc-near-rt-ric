name: O-RAN Near-RT RIC CI/CD Pipeline

on:
  push:
    branches: [ main, develop, 'feature/**', 'release/**' ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly builds at 2 AM UTC
    - cron: '0 2 * * *'

env:
  # Container registry configuration
  REGISTRY: ghcr.io
  REGISTRY_USERNAME: ${{ github.actor }}
  REGISTRY_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
  
  # Go configuration
  GO_VERSION: '1.21'
  GOLANGCI_LINT_VERSION: 'v1.54'
  
  # Node.js configuration
  NODE_VERSION: '18'
  
  # Kubernetes configuration
  KIND_VERSION: 'v0.20.0'
  KUBECTL_VERSION: 'v1.29.0'
  HELM_VERSION: 'v3.13.0'
  
  # O-RAN specific configuration
  ORAN_NAMESPACE: 'oran-nearrt-ric'
  E2_SIMULATOR_TIMEOUT: '300s'

jobs:
  # Security scanning and dependency check
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      contents: read
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Check for secrets
      uses: gitleaks/gitleaks-action@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Code quality and linting
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write # å…è¨±ä¸Šå‚³ SARIF æŽƒæçµæžœ
    strategy:
      matrix:
        component: ['main-dashboard', 'xapp-dashboard']
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Go
      if: matrix.component == 'main-dashboard'
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true
        cache-dependency-path: 'dashboard-master/dashboard-master/go.sum'

    - name: Cache Go dependencies
      if: matrix.component == 'main-dashboard'
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Setup Node.js
      if: matrix.component == 'xapp-dashboard'
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: 'xAPP_dashboard-master/package-lock.json'

    - name: Cache Node.js dependencies
      if: matrix.component == 'xapp-dashboard'
      uses: actions/cache@v3
      with:
        path: |
          ~/.npm
          xAPP_dashboard-master/node_modules
        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-node-

    # Go linting and testing
    - name: Go mod download
      if: matrix.component == 'main-dashboard'
      working-directory: dashboard-master/dashboard-master
      timeout-minutes: 10
      run: |
        # Retry go mod download up to 3 times
        for attempt in 1 2 3; do
          echo "Attempt $attempt: Downloading Go modules..."
          if go mod download; then
            echo "go mod download succeeded on attempt $attempt"
            break
          else
            echo "go mod download failed on attempt $attempt"
            if [ $attempt -eq 3 ]; then
              echo "All go mod download attempts failed"
              exit 1
            fi
            sleep_time=$((attempt * 5))
            echo "Waiting ${sleep_time}s before retry..."
            sleep $sleep_time
            go clean -modcache
          fi
        done

    - name: Run golangci-lint
      if: matrix.component == 'main-dashboard'
      uses: golangci/golangci-lint-action@v3
      timeout-minutes: 20
      with:
        version: ${{ env.GOLANGCI_LINT_VERSION }}
        working-directory: dashboard-master/dashboard-master
        args: --timeout=15m --config=.golangci.yml
        skip-cache: false
        skip-pkg-cache: false
        skip-build-cache: false

    - name: Run Go tests
      if: matrix.component == 'main-dashboard'
      working-directory: dashboard-master/dashboard-master
      timeout-minutes: 15
      run: |
        go test -v -race -coverprofile=coverage.out -covermode=atomic ./...
        go tool cover -html=coverage.out -o coverage.html

    - name: Go Security Scan (gosec & govulncheck)
      if: matrix.component == 'main-dashboard'
      working-directory: dashboard-master/dashboard-master
      run: |
        # Install security scanning tools
        go install github.com/securego/gosec/v2/cmd/gosec@latest
        go install golang.org/x/vuln/cmd/govulncheck@latest
        
        # Run gosec scan
        gosec -no-fail -fmt sarif -out ../../gosec-results.sarif ./...
        
        # Run govulncheck for vulnerability scanning
        govulncheck -json ./... > ../../govulncheck-results.json || true

    - name: Upload Gosec Scan Results to GitHub Security tab
      if: matrix.component == 'main-dashboard'
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: 'gosec-results.sarif'

    # Node.js linting and testing
    - name: Install Node.js dependencies
      if: matrix.component == 'xapp-dashboard'
      working-directory: xAPP_dashboard-master
      timeout-minutes: 15
      run: |
        # Retry npm ci up to 3 times with exponential backoff
        for attempt in 1 2 3; do
          echo "Attempt $attempt: Installing Node.js dependencies..."
          if npm ci --cache ~/.npm --prefer-offline --no-audit --progress=false; then
            echo "npm ci succeeded on attempt $attempt"
            break
          else
            echo "npm ci failed on attempt $attempt"
            if [ $attempt -eq 3 ]; then
              echo "All npm ci attempts failed"
              exit 1
            fi
            sleep_time=$((attempt * 10))
            echo "Waiting ${sleep_time}s before retry..."
            sleep $sleep_time
            npm cache clean --force
          fi
        done

    - name: Run ESLint
      if: matrix.component == 'xapp-dashboard'
      working-directory: xAPP_dashboard-master
      timeout-minutes: 10
      run: npm run lint

    - name: Run Angular tests
      if: matrix.component == 'xapp-dashboard'
      working-directory: xAPP_dashboard-master
      timeout-minutes: 15
      run: npm run test:ci

    - name: Run e2e tests
      if: matrix.component == 'xapp-dashboard'
      working-directory: xAPP_dashboard-master
      run: npm run e2e:ci

    - name: Node.js Security Scan (npm audit)
      if: matrix.component == 'xapp-dashboard'
      working-directory: xAPP_dashboard-master
      run: |
        # Run npm audit for vulnerability scanning
        npm audit --audit-level=moderate --json > ../npm-audit-results.json || true
        
        # Run npm audit fix for auto-fixable issues (non-breaking changes only)
        npm audit fix --audit-level=moderate || true

    # Upload coverage reports
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: always()
      timeout-minutes: 5
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./dashboard-master/dashboard-master/coverage.out,./xAPP_dashboard-master/coverage/lcov.info
        flags: ${{ matrix.component }}
        name: ${{ matrix.component }}-coverage
        fail_ci_if_error: false
        verbose: true

  # Build and test
  build-test:
    name: Build and Test
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [security-scan, code-quality]
    strategy:
      matrix:
        component: 
        - name: 'main-dashboard'
          path: 'dashboard-master/dashboard-master'
          dockerfile: 'aio/Dockerfile'
        - name: 'xapp-dashboard'
          path: 'xAPP_dashboard-master'
          dockerfile: 'Dockerfile'
        - name: 'fl-coordinator'
          path: 'dashboard-master/dashboard-master'
          dockerfile: 'aio/Dockerfile.fl'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ env.REGISTRY_USERNAME }}
        password: ${{ env.REGISTRY_PASSWORD }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.component.name }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-,suffix=-{{date 'YYYYMMDD-HHmmss'}}
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      timeout-minutes: 45
      with:
        context: ${{ matrix.component.path }}
        file: ${{ matrix.component.path }}/${{ matrix.component.dockerfile }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64
        build-args: |
          BUILDTIME=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.created'] }}
          VERSION=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.version'] }}
          REVISION=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.revision'] }}
        provenance: false
        sbom: false

  # Helm chart testing
  helm-test:
    name: Helm Chart Test
    runs-on: ubuntu-latest
    needs: [security-scan]
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Helm
      uses: azure/setup-helm@v3
      with:
        version: ${{ env.HELM_VERSION }}

    - name: Cache Helm charts
      uses: actions/cache@v3
      with:
        path: ~/.cache/helm
        key: ${{ runner.os }}-helm-${{ hashFiles('helm/oran-nearrt-ric/Chart.yaml') }}
        restore-keys: |
          ${{ runner.os }}-helm-

    - name: Add Helm repositories
      run: |
        # Add repositories with retry logic
        for i in {1..3}; do
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts && break
          echo "Attempt $i failed, retrying in 10s..."
          sleep 10
        done
        
        for i in {1..3}; do
          helm repo add grafana https://grafana.github.io/helm-charts && break
          echo "Attempt $i failed, retrying in 10s..."
          sleep 10
        done
        
        for i in {1..3}; do
          helm repo add bitnami https://charts.bitnami.com/bitnami && break
          echo "Attempt $i failed, retrying in 10s..."
          sleep 10
        done
        
        for i in {1..3}; do
          helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/ && break
          echo "Attempt $i failed, retrying in 10s..."
          sleep 10
        done
        
        for i in {1..3}; do
          helm repo update && break
          echo "Helm repo update attempt $i failed, retrying in 10s..."
          sleep 10
        done

    - name: Update Helm dependencies
      run: |
        helm dependency update ./helm/oran-nearrt-ric

    - name: Lint Helm chart
      run: |
        helm lint helm/oran-nearrt-ric/
        helm template oran-nearrt-ric helm/oran-nearrt-ric/ --debug --dry-run

    - name: Run chart-testing (lint)
      uses: helm/chart-testing-action@v2.6.0
      with:
        command: lint
        config: .github/ct.yaml

    - name: Create KIND cluster for testing
      uses: helm/kind-action@v1.8.0
      with:
        version: ${{ env.KIND_VERSION }}
        config: kind-config.yaml
        cluster_name: chart-testing

    - name: Run chart-testing (install)
      uses: helm/chart-testing-action@v2.6.0
      with:
        command: install
        config: .github/ct.yaml

  # End-to-end testing
  e2e-test:
    name: E2E Testing
    runs-on: ubuntu-latest
    needs: [build-test]
    if: github.event_name != 'schedule'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: ${{ env.KUBECTL_VERSION }}

    - name: Set up Helm
      uses: azure/setup-helm@v3
      with:
        version: ${{ env.HELM_VERSION }}

    - name: Create KIND cluster
      uses: helm/kind-action@v1.8.0
      with:
        version: ${{ env.KIND_VERSION }}
        config: kind-config.yaml
        cluster_name: e2e-testing

    - name: Load Docker images into KIND
      run: |
        # Load built images into KIND cluster
        kind load docker-image ${{ env.REGISTRY }}/${{ github.repository }}/main-dashboard:${{ github.sha }} --name e2e-testing
        kind load docker-image ${{ env.REGISTRY }}/${{ github.repository }}/xapp-dashboard:${{ github.sha }} --name e2e-testing
        kind load docker-image ${{ env.REGISTRY }}/${{ github.repository }}/fl-coordinator:${{ github.sha }} --name e2e-testing

    - name: Deploy O-RAN platform
      timeout-minutes: 10
      run: |
        # Create namespaces
        kubectl create namespace ${{ env.ORAN_NAMESPACE }}
        kubectl create namespace kubernetes-dashboard
        kubectl create namespace xapp-dashboard
        kubectl create namespace monitoring
        
        # Deploy components with test images
        helm install oran-nearrt-ric helm/oran-nearrt-ric/ \
          --namespace ${{ env.ORAN_NAMESPACE }} \
          --set mainDashboard.image.tag=${{ github.sha }} \
          --set xappDashboard.image.tag=${{ github.sha }} \
          --set federatedLearning.image.tag=${{ github.sha }} \
          --set global.imageRegistry=${{ env.REGISTRY }}/${{ github.repository }} \
          --wait --timeout=10m

    - name: Wait for deployments
      timeout-minutes: 10
      run: |
        # Wait for deployments with retry logic
        for deployment in main-dashboard xapp-dashboard e2-simulator; do
          echo "Waiting for deployment: $deployment"
          for attempt in 1 2 3; do
            if kubectl wait --for=condition=available deployment/$deployment \
              --namespace=${{ env.ORAN_NAMESPACE }} --timeout=300s; then
              echo "Deployment $deployment is ready"
              break
            else
              echo "Deployment $deployment not ready on attempt $attempt"
              if [ $attempt -eq 3 ]; then
                echo "Deployment $deployment failed to become ready"
                kubectl describe deployment/$deployment --namespace=${{ env.ORAN_NAMESPACE }}
                kubectl logs -l app=$deployment --namespace=${{ env.ORAN_NAMESPACE }} --tail=50
                exit 1
              fi
              sleep 30
            fi
          done
        done

    - name: Run E2E tests
      timeout-minutes: 20
      run: |
        # Function for retrying commands
        retry_command() {
          local cmd="$1"
          local desc="$2"
          for attempt in 1 2 3; do
            echo "Attempt $attempt: $desc"
            if eval "$cmd"; then
              echo "$desc succeeded on attempt $attempt"
              return 0
            else
              echo "$desc failed on attempt $attempt"
              if [ $attempt -eq 3 ]; then
                echo "All attempts failed for: $desc"
                return 1
              fi
              sleep 10
            fi
          done
        }
        
        # Test E2 Interface connectivity
        retry_command "kubectl exec -n ${{ env.ORAN_NAMESPACE }} deployment/e2-simulator -- nc -z e2-termination 38000" "E2 Interface connectivity test"
          
        # Test A1 Interface connectivity  
        retry_command "kubectl exec -n ${{ env.ORAN_NAMESPACE }} deployment/a1-mediator -- curl -f http://localhost:10020/a1-p/healthcheck" "A1 Interface connectivity test"
          
        # Test xApp registration with FL Coordinator
        retry_command "kubectl exec -n ${{ env.ORAN_NAMESPACE }} deployment/resource-allocation-xapp -- curl -f http://fl-coordinator:8080/fl/clients" "xApp registration test"
          
        # Test dashboard accessibility
        kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8080:443 &
        sleep 15
        retry_command "curl -k -f https://localhost:8080/api/v1/login/status" "Dashboard accessibility test"
        
        # Test metrics collection
        kubectl port-forward -n monitoring service/prometheus-server 9090:80 &
        sleep 15
        retry_command "curl -f http://localhost:9090/-/healthy" "Metrics collection test"

    - name: Collect logs on failure
      if: failure()
      timeout-minutes: 10
      run: |
        echo "=== Collecting diagnostic information on failure ==="
        
        echo "=== Cluster Overview ==="
        kubectl get all -A || true
        
        echo "=== Node Status ==="
        kubectl get nodes -o wide || true
        kubectl describe nodes || true
        
        echo "=== Pod Details ==="
        kubectl get pods -n ${{ env.ORAN_NAMESPACE }} -o wide || true
        kubectl describe pods -n ${{ env.ORAN_NAMESPACE }} || true
        
        echo "=== Service and Ingress Status ==="
        kubectl get svc,ingress -n ${{ env.ORAN_NAMESPACE }} || true
        
        echo "=== Events ==="
        kubectl get events -n ${{ env.ORAN_NAMESPACE }} --sort-by='.lastTimestamp' || true
        
        echo "=== Application Logs ==="
        for deployment in main-dashboard xapp-dashboard e2-simulator a1-mediator fl-coordinator; do
          echo "--- Logs for $deployment ---"
          kubectl logs -n ${{ env.ORAN_NAMESPACE }} deployment/$deployment --tail=100 --previous=false || true
          if kubectl get deployment/$deployment -n ${{ env.ORAN_NAMESPACE }} &>/dev/null; then
            kubectl logs -n ${{ env.ORAN_NAMESPACE }} deployment/$deployment --tail=100 --previous=true || true
          fi
        done
        
        echo "=== Resource Usage ==="
        kubectl top nodes || true
        kubectl top pods -n ${{ env.ORAN_NAMESPACE }} || true
        
        echo "=== Storage and PVC Status ==="
        kubectl get pv,pvc -A || true

  # Performance testing
  performance-test:
    name: Performance Test
    runs-on: ubuntu-latest
    needs: [e2e-test]
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[perf-test]')
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: ${{ env.KUBECTL_VERSION }}

    - name: Create KIND cluster for performance testing
      uses: helm/kind-action@v1.8.0
      with:
        version: ${{ env.KIND_VERSION }}
        config: kind-config.yaml
        cluster_name: perf-testing

    - name: Deploy O-RAN platform for performance testing
      run: |
        helm install oran-nearrt-ric helm/oran-nearrt-ric/ \
          --namespace ${{ env.ORAN_NAMESPACE }} \
          --create-namespace \
          --set mainDashboard.replicaCount=3 \
          --set xappDashboard.replicaCount=3 \
          --set xapps.resourceAllocation.replicaCount=2 \
          --set e2Simulator.replicaCount=3 \
          --wait --timeout=15m

    - name: Run load tests
      run: |
        # Install k6 for load testing
        sudo gpg -k
        sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
        
        # Run load tests against the platform
        kubectl port-forward -n ${{ env.ORAN_NAMESPACE }} service/main-dashboard 8080:8080 &
        kubectl port-forward -n ${{ env.ORAN_NAMESPACE }} service/fl-coordinator 8090:8080 &
        sleep 10
        
        # Create k6 test script
        cat > load-test.js << 'EOF'
        import http from 'k6/http';
        import { check } from 'k6';
        
        export let options = {
          stages: [
            { duration: '2m', target: 10 },
            { duration: '5m', target: 50 },
            { duration: '2m', target: 100 },
            { duration: '5m', target: 100 },
            { duration: '2m', target: 0 },
          ],
          thresholds: {
            http_req_duration: ['p(95)<500'],
            http_req_failed: ['rate<0.1'],
          },
        };
        
        export default function () {
          let response = http.get('http://localhost:8080/api/v1/login/status');
          check(response, {
            'status is 200': (r) => r.status === 200,
            'response time < 500ms': (r) => r.timings.duration < 500,
          });
          
          response = http.get('http://localhost:8090/fl/clients');
          check(response, {
            'FL coordinator healthy': (r) => r.status === 200,
          });
        }
        EOF
        
        k6 run load-test.js

    - name: Generate performance report
      if: always()
      run: |
        kubectl top nodes
        kubectl top pods -n ${{ env.ORAN_NAMESPACE }}
        kubectl get hpa -n ${{ env.ORAN_NAMESPACE }}

  # Deployment to staging/production
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    needs: [e2e-test, helm-test]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: 
      name: staging
      url: https://oran-staging.example.com
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: ${{ env.KUBECTL_VERSION }}

    - name: Set up Helm
      uses: azure/setup-helm@v3
      with:
        version: ${{ env.HELM_VERSION }}

    - name: Configure kubectl for staging
      run: |
        # Configure kubectl context for staging cluster
        # This would typically involve setting up kubeconfig with staging cluster credentials
        echo "Configuring kubectl for staging deployment..."
        # kubectl config set-cluster staging --server=${{ secrets.STAGING_CLUSTER_SERVER }}
        # kubectl config set-credentials staging-user --token=${{ secrets.STAGING_CLUSTER_TOKEN }}
        # kubectl config set-context staging --cluster=staging --user=staging-user
        # kubectl config use-context staging

    - name: Deploy to staging
      run: |
        helm upgrade --install oran-nearrt-ric helm/oran-nearrt-ric/ \
          --namespace ${{ env.ORAN_NAMESPACE }} \
          --create-namespace \
          --set global.imageRegistry=${{ env.REGISTRY }}/${{ github.repository }} \
          --set mainDashboard.image.tag=${{ github.sha }} \
          --set xappDashboard.image.tag=${{ github.sha }} \
          --set federatedLearning.image.tag=${{ github.sha }} \
          --set mainDashboard.ingress.enabled=true \
          --set mainDashboard.ingress.hosts[0].host=oran-staging.example.com \
          --set mainDashboard.ingress.hosts[0].paths[0].path=/ \
          --set mainDashboard.ingress.hosts[0].paths[0].pathType=Prefix \
          --wait --timeout=10m

    - name: Verify deployment
      run: |
        kubectl rollout status deployment/main-dashboard -n ${{ env.ORAN_NAMESPACE }}
        kubectl rollout status deployment/xapp-dashboard -n ${{ env.ORAN_NAMESPACE }}
        kubectl get ingress -n ${{ env.ORAN_NAMESPACE }}

    - name: Run smoke tests
      run: |
        # Run basic smoke tests against staging environment
        echo "Running smoke tests against staging..."
        # curl -f https://oran-staging.example.com/health
        # curl -f https://oran-staging.example.com/api/v1/login/status

  # Release creation
  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: [deploy]
    if: startsWith(github.ref, 'refs/tags/v')
    permissions:
      contents: write
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Generate changelog
      id: changelog
      run: |
        # Generate comprehensive changelog from git commits
        echo "CHANGELOG<<EOF" >> $GITHUB_OUTPUT
        
        # Get previous tag
        PREVIOUS_TAG=$(git describe --tags --abbrev=0 HEAD^ 2>/dev/null || echo "")
        
        if [ -n "$PREVIOUS_TAG" ]; then
          echo "## Changes since $PREVIOUS_TAG" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          
          # Categorize commits
          echo "### ðŸš€ Features" >> $GITHUB_OUTPUT
          git log --pretty=format:"- %s" $PREVIOUS_TAG..HEAD | grep -E "^- (feat|feature)" >> $GITHUB_OUTPUT || echo "- No new features" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          
          echo "### ðŸ› Bug Fixes" >> $GITHUB_OUTPUT
          git log --pretty=format:"- %s" $PREVIOUS_TAG..HEAD | grep -E "^- (fix|bugfix)" >> $GITHUB_OUTPUT || echo "- No bug fixes" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          
          echo "### ðŸ“š Documentation" >> $GITHUB_OUTPUT
          git log --pretty=format:"- %s" $PREVIOUS_TAG..HEAD | grep -E "^- (docs|doc)" >> $GITHUB_OUTPUT || echo "- No documentation changes" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          
          echo "### ðŸ”§ Other Changes" >> $GITHUB_OUTPUT
          git log --pretty=format:"- %s" $PREVIOUS_TAG..HEAD | grep -vE "^- (feat|feature|fix|bugfix|docs|doc)" >> $GITHUB_OUTPUT || echo "- No other changes" >> $GITHUB_OUTPUT
        else
          echo "## Initial Release" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          git log --pretty=format:"- %s" >> $GITHUB_OUTPUT
        fi
        
        echo "EOF" >> $GITHUB_OUTPUT

    - name: Create GitHub Release
      uses: softprops/action-gh-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref_name }}
        name: O-RAN Near-RT RIC ${{ github.ref_name }}
        body: |
          ## What's Changed
          ${{ steps.changelog.outputs.CHANGELOG }}
          
          ## Docker Images
          - Main Dashboard: `${{ env.REGISTRY }}/${{ github.repository }}/main-dashboard:${{ github.ref_name }}`
          - xApp Dashboard: `${{ env.REGISTRY }}/${{ github.repository }}/xapp-dashboard:${{ github.ref_name }}`
          - FL Coordinator: `${{ env.REGISTRY }}/${{ github.repository }}/fl-coordinator:${{ github.ref_name }}`
          
          ## Helm Chart
          ```bash
          helm install oran-nearrt-ric oci://${{ env.REGISTRY }}/${{ github.repository }}/helm/oran-nearrt-ric --version ${{ github.ref_name }}
          ```
          
          ## Quick Start
          ```bash
          git clone [https://github.com/$](https://github.com/$){{ github.repository }}.git
          cd near-rt-ric
          git checkout ${{ github.ref_name }}
          ./scripts/setup.sh
          ```
        draft: false
        prerelease: ${{ contains(github.ref_name, 'rc') || contains(github.ref_name, 'beta') || contains(github.ref_name, 'alpha') }}

  # Cleanup
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [e2e-test, performance-test]
    if: always()
    steps:
    - name: Delete old container images
      run: |
        # Keep only the latest 10 versions of each image
        echo "Cleaning up old container images..."
        # This would typically involve calling the GitHub Packages API
        # to delete old image versions
